{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reedhyde/reedsstuff/blob/main/07_demographics_filtered_solution_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTc61chZZy5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82af448b-cc38-49a4-a35d-b1f1c527c390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [60.9 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,545 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,503 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,790 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,627 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,429 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,550 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,516 kB]\n",
            "Fetched 26.6 MB in 5s (5,243 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.x  from https://downloads.apache.org/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.5.1'\n",
        "spark_version = 'spark-3.5.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz9FFdrHB6TO"
      },
      "outputs": [],
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"demographicsFilter\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ8AzEZdZvuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80820e40-2f9c-4188-e5a5-7a141b332bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n",
            "| id|             name|age|height_m|weight_kg|children|          occupation|academic_degree|salary|            location|\n",
            "+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n",
            "|  1|    Glad Gavrieli| 38|    1.52|       74|       0|Computer Systems ...|       Bachelor|    78|           Louisiana|\n",
            "|  2|  Henrieta Fittes| 34|    1.72|       39|       4|             Teacher|         Master|    44|            Illinois|\n",
            "|  3|   Peyton Dulanty| 24|     1.8|       47|       5|Senior Quality En...|            PhD|    44|      North Carolina|\n",
            "|  4|     Denna Morgen| 48|    1.81|       71|       5|   Account Executive|         Master|    81|          California|\n",
            "|  5|    Camella Izaks| 34|    1.65|       60|       1|   Director of Sales|            PhD|    76|                Ohio|\n",
            "|  6|     Shara Esposi| 49|     1.5|       52|       2|     Sales Associate|         Master|    68|            Virginia|\n",
            "|  7|Saunderson Gudgen| 64|    1.93|       47|       0|Sales Representative|         Master|    85|            New York|\n",
            "|  8|Aldrich Rosendorf| 42|    1.77|       66|       0|        Developer II|            PhD|    84|District of Columbia|\n",
            "|  9| Edlin Washington| 50|    1.74|       52|       4|     Design Engineer|         Master|    88|              Oregon|\n",
            "| 10| Anders Penwright| 55|    1.98|       90|       2|     Project Manager|       Bachelor|   116|             Georgia|\n",
            "| 11|   Ruthie Cubbini| 67|    1.52|       55|       4|     Data Coordiator|            PhD|    51|District of Columbia|\n",
            "| 12|  Juliet Harbidge| 66|    1.61|       49|       2|             Actuary|            PhD|    66|         Mississippi|\n",
            "| 13|  Jeannine Kelner| 30|     1.8|       81|       1|       Programmer II|       Bachelor|    90|              Hawaii|\n",
            "| 14|  Roi Gristhwaite| 66|    1.86|       90|       1|    Product Engineer|       Bachelor|    40|           Tennessee|\n",
            "| 15|      Brant Stark| 58|    1.94|       53|       4|Sales Representative|       Bachelor|    96|      North Carolina|\n",
            "| 16|   Donny Rankling| 26|    1.51|       39|       1|Physical Therapy ...|       Bachelor|   116|            Virginia|\n",
            "| 17|     Dov Gavaghan| 27|    1.58|       68|       5|Computer Systems ...|       Bachelor|    74|                Utah|\n",
            "| 18|    Rosanne Wreak| 37|    1.76|       81|       2|Payment Adjustmen...|         Master|   103|             Florida|\n",
            "| 19|    Belva Spraggs| 50|    1.65|       80|       2|             Teacher|       Bachelor|    46|             Georgia|\n",
            "| 20|      Welch Lease| 21|    1.57|       79|       4|Mechanical System...|         Master|   114|       Massachusetts|\n",
            "+---+-----------------+---+--------+---------+--------+--------------------+---------------+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/1/demographics.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.option('header', 'true').csv(SparkFiles.get(\"demographics.csv\"), inferSchema=True, sep=',')\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZFco7ARZvuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9396155-16dc-4ced-d9a8-42c82400f24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------+\n",
            "|         occupation|Salary|\n",
            "+-------------------+------+\n",
            "|Assistant Professor|   120|\n",
            "|       Food Chemist|   120|\n",
            "|   Product Engineer|   120|\n",
            "|Electrical Engineer|   120|\n",
            "|  Chemical Engineer|   120|\n",
            "+-------------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# What occupation had the highest salary?\n",
        "df.orderBy(df[\"Salary\"].desc()).select(\"occupation\", \"Salary\").limit(5).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"occupation\", \"Salary\").max().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "T6b_xDMtcI16",
        "outputId": "29d5c81f-fd52-424f-8e5f-e5f72ead0eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'max'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b13b23ebbf15>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"occupation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Salary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.5.3-bin-hadoop3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3127\u001b[0m         \"\"\"\n\u001b[1;32m   3128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3129\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   3130\u001b[0m                 \u001b[0;34m\"'%s' object has no attribute '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'max'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdj33caiZvuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ddd808-64ac-4ba2-fef5-1c6506046b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------+\n",
            "|      occupation|Salary|\n",
            "+----------------+------+\n",
            "|Product Engineer|    40|\n",
            "+----------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# What occupation had the lowest salary?\n",
        "df.orderBy(df[\"Salary\"]).select(\"occupation\", \"Salary\").limit(1).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CifAfVSzZvun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51303420-cc27-4496-fc43-5a6380a73ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|avg(Salary)|\n",
            "+-----------+\n",
            "|     79.475|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# What is the average salary of this dataset?\n",
        "from pyspark.sql.functions import avg\n",
        "df.select(avg(\"Salary\")).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G8P0_Pba69K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea323ad9-c7de-4371-81ca-2bc6b53013fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|max(Salary)|min(Salary)|\n",
            "+-----------+-----------+\n",
            "|        120|         40|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# What is the max and min of the Salary column?\n",
        "from pyspark.sql.functions import max, min\n",
        "df.select(max(\"Salary\"), min(\"Salary\")).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHyNTIS7Zvur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e70a14-61c6-4ba9-f4b6-563ea7ded830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|          occupation|\n",
            "+--------------------+\n",
            "|   Account Executive|\n",
            "|Sales Representative|\n",
            "|        Developer II|\n",
            "|     Design Engineer|\n",
            "|     Project Manager|\n",
            "|       Programmer II|\n",
            "|Sales Representative|\n",
            "|Physical Therapy ...|\n",
            "|Payment Adjustmen...|\n",
            "|Mechanical System...|\n",
            "|     Media Manager I|\n",
            "|   Account Executive|\n",
            "|           Professor|\n",
            "|Community Outreac...|\n",
            "| Clinical Specialist|\n",
            "|Human Resources A...|\n",
            "|Nuclear Power Eng...|\n",
            "|      Civil Engineer|\n",
            "|Human Resources M...|\n",
            "|Senior Cost Accou...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show all of the occupations where salaries were above 80k\n",
        "# from pyspark.sql.functions import count\n",
        "df.filter(\"Salary > 80\").select(\"occupation\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAmRujSRZvuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8cb076-ce5f-4eae-e52c-4e6bb91b5430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------------------+------------------+\n",
            "|academic_degree|          avg(age)|     avg(height_m)|\n",
            "+---------------+------------------+------------------+\n",
            "|            PhD| 42.87818696883853|1.7537393767705372|\n",
            "|         Master|42.105095541401276|1.7606050955414014|\n",
            "|       Bachelor| 43.85585585585586|1.7371771771771771|\n",
            "+---------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# BONUS\n",
        "# What is the average age and height for each academic degree type?\n",
        "# HINT: You will need to use `groupby` to solve this\n",
        "avg_df = df.groupBy(\"academic_degree\").avg()\n",
        "avg_df.select(\"academic_degree\", \"avg(age)\", \"avg(height_m)\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UeorfXUc-X7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}